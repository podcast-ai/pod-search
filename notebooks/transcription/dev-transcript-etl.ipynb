{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript ETL Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandera.typing import DataFrame\n",
    "\n",
    "import pandas\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir = Path(\"/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/\")\n",
    "project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/data/podcasts')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_dir = project_dir / \"data/podcasts/\"\n",
    "podcast_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/data/transcripts/Google')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_dir = project_dir / \"data/transcripts/Google\"\n",
    "transcript_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220617 lex_ai_richard_wolff.json   20220628 lex_ai_susan_cain.vtt\n",
      "20220617 lex_ai_richard_wolff.vtt    20220701 lex_ai_demis_hassabis.json\n",
      "20220628 lex_ai_susan_cain.json      20220701 lex_ai_demis_hassabis.vtt\n"
     ]
    }
   ],
   "source": [
    "ls {transcript_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_transcript_path = transcript_dir / \"20220701 lex_ai_demis_hassabis.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_transcript_to_dataframe(\n",
    "    path,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Parse Google Speech to Text API result .json -> pandas.DataFrame\"\"\"\n",
    "    transcript_data = pandas.read_json(path)\n",
    "    return transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2vec_transcript_to_dataframe(\n",
    "    path,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Parse Wav2Vec result .csv -> pandas.DataFrame\"\"\"\n",
    "    transcript_data = pandas.read_csv(path)\n",
    "    return transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_google_transcript(\n",
    "    path,\n",
    "    episode_id: int = None,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Parse Google Speech to Text API result .json -> pandas.DataFrame\"\"\"\n",
    "    transcript_data = pandas.read_json(path)\n",
    "    #transcript_data[\"file_name\"] = path.stem\n",
    "    transcript_data[\"episode_id\"] = episode_id\n",
    "    return transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_google_transcript(\n",
    "    transcript_data,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Clean Google Speech to Text API result.\"\"\"\n",
    "    transcript_data = (\n",
    "        transcript_data\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"start\": \"chunk_start\",\n",
    "                \"end\": \"chunk_end\",\n",
    "                \"newpara\": \"new_paragraph\"\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    transcript_data[\"new_paragraph\"] = transcript_data[\"new_paragraph\"].fillna(0.0).astype(bool)\n",
    "    transcript_data[\"chunk_number\"] = transcript_data.index\n",
    "    # enumerate paragraphs\n",
    "    transcript_data[\"paragraph_number\"] = transcript_data[\"new_paragraph\"].cumsum()\n",
    "    transcript_data = transcript_data.drop(columns=[\"new_paragraph\"])\n",
    "    return transcript_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(\n",
    "    transcript_dir,\n",
    "):\n",
    "    \"\"\"Process all transcripts in a directory.\"\"\"\n",
    "    transcript_paths = [\n",
    "        p for p in transcript_dir.glob(\"*.json\")\n",
    "    ]\n",
    "    transcript_data = [\n",
    "        clean_google_transcript(parse_google_transcript(path, episode_id)) for episode_id, path in enumerate(transcript_paths)\n",
    "    ]\n",
    "    episode_data = pandas.DataFrame(\n",
    "        [\n",
    "            {\"episode_id\": episode_id, \"file_name\": path.stem}\n",
    "            for episode_id, path in enumerate(transcript_paths)\n",
    "        ]\n",
    "    )\n",
    "    transcript_data = pandas.concat(transcript_data)\n",
    "    transcript_data = transcript_data.set_index([\"episode_id\", \"chunk_number\"])\n",
    "    episode_data = episode_data.set_index(\"episode_id\")\n",
    "    return transcript_data, episode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- chunk enumeration\n",
    "- file id / name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th>paragraph_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>6.398</td>\n",
       "      <td>The following is a conversation with demouth c...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.602</td>\n",
       "      <td>16.615</td>\n",
       "      <td>A company that has published and build some of...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.828</td>\n",
       "      <td>30.299</td>\n",
       "      <td>All by itself to play the game of Go better th...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.088</td>\n",
       "      <td>40.678</td>\n",
       "      <td>Thomas is widely considered to be one of the m...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.873</td>\n",
       "      <td>50.563</td>\n",
       "      <td>This was truly an honor and a pleasure for me ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>8172.342</td>\n",
       "      <td>8184.166</td>\n",
       "      <td>Human beings in this giant puzzle of ours and ...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>None</td>\n",
       "      <td>921</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>8184.954</td>\n",
       "      <td>8191.394</td>\n",
       "      <td>Thanks for listening to this conversation with...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>None</td>\n",
       "      <td>922</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>8191.689</td>\n",
       "      <td>8195.580</td>\n",
       "      <td>And now let me leave you with some words from ...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>None</td>\n",
       "      <td>923</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>8196.244</td>\n",
       "      <td>8202.197</td>\n",
       "      <td>Computer science is no more about computers an...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>None</td>\n",
       "      <td>924</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>8207.280</td>\n",
       "      <td>8222.328</td>\n",
       "      <td>Music.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>925</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>926 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunk_start  chunk_end  \\\n",
       "0          0.018      6.398   \n",
       "1          6.602     16.615   \n",
       "2         16.828     30.299   \n",
       "3         31.088     40.678   \n",
       "4         40.873     50.563   \n",
       "..           ...        ...   \n",
       "921     8172.342   8184.166   \n",
       "922     8184.954   8191.394   \n",
       "923     8191.689   8195.580   \n",
       "924     8196.244   8202.197   \n",
       "925     8207.280   8222.328   \n",
       "\n",
       "                                                  text  confidence episode_id  \\\n",
       "0    The following is a conversation with demouth c...        0.80       None   \n",
       "1    A company that has published and build some of...        0.88       None   \n",
       "2    All by itself to play the game of Go better th...        0.90       None   \n",
       "3    Thomas is widely considered to be one of the m...        0.80       None   \n",
       "4    This was truly an honor and a pleasure for me ...        0.88       None   \n",
       "..                                                 ...         ...        ...   \n",
       "921  Human beings in this giant puzzle of ours and ...        0.81       None   \n",
       "922  Thanks for listening to this conversation with...        0.81       None   \n",
       "923  And now let me leave you with some words from ...        0.91       None   \n",
       "924  Computer science is no more about computers an...        0.91       None   \n",
       "925                                             Music.         NaN       None   \n",
       "\n",
       "     chunk_number  paragraph_number  \n",
       "0               0                 1  \n",
       "1               1                 1  \n",
       "2               2                 1  \n",
       "3               3                 2  \n",
       "4               4                 2  \n",
       "..            ...               ...  \n",
       "921           921               203  \n",
       "922           922               204  \n",
       "923           923               205  \n",
       "924           924               206  \n",
       "925           925               207  \n",
       "\n",
       "[926 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_data = clean_google_transcript(\n",
    "    parse_google_transcript(\n",
    "        transcript_dir / \"20220701 lex_ai_demis_hassabis.json\"\n",
    "    )\n",
    ")\n",
    "transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data, episode_data = process_transcripts(\n",
    "    transcript_dir=transcript_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220701 lex_ai_demis_hassabis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220617 lex_ai_richard_wolff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220628 lex_ai_susan_cain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name\n",
       "episode_id                                \n",
       "0           20220701 lex_ai_demis_hassabis\n",
       "1            20220617 lex_ai_richard_wolff\n",
       "2               20220628 lex_ai_susan_cain"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>paragraph_number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>6.398</td>\n",
       "      <td>The following is a conversation with demouth c...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.602</td>\n",
       "      <td>16.615</td>\n",
       "      <td>A company that has published and build some of...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.828</td>\n",
       "      <td>30.299</td>\n",
       "      <td>All by itself to play the game of Go better th...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.088</td>\n",
       "      <td>40.678</td>\n",
       "      <td>Thomas is widely considered to be one of the m...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.873</td>\n",
       "      <td>50.563</td>\n",
       "      <td>This was truly an honor and a pleasure for me ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>864</th>\n",
       "      <td>7495.120</td>\n",
       "      <td>7503.117</td>\n",
       "      <td>If you'll accept really strong emotions someti...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>7503.708</td>\n",
       "      <td>7511.174</td>\n",
       "      <td>Highly sensitive people also process informati...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>7511.783</td>\n",
       "      <td>7521.274</td>\n",
       "      <td>They tend to notice so these that others miss ...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>7522.478</td>\n",
       "      <td>7525.730</td>\n",
       "      <td>Thank you for listening and hope to see you ne...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>7526.960</td>\n",
       "      <td>7542.264</td>\n",
       "      <td>Music.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3037 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         chunk_start  chunk_end  \\\n",
       "episode_id chunk_number                           \n",
       "0          0                   0.018      6.398   \n",
       "           1                   6.602     16.615   \n",
       "           2                  16.828     30.299   \n",
       "           3                  31.088     40.678   \n",
       "           4                  40.873     50.563   \n",
       "...                              ...        ...   \n",
       "2          864              7495.120   7503.117   \n",
       "           865              7503.708   7511.174   \n",
       "           866              7511.783   7521.274   \n",
       "           867              7522.478   7525.730   \n",
       "           868              7526.960   7542.264   \n",
       "\n",
       "                                                                      text  \\\n",
       "episode_id chunk_number                                                      \n",
       "0          0             The following is a conversation with demouth c...   \n",
       "           1             A company that has published and build some of...   \n",
       "           2             All by itself to play the game of Go better th...   \n",
       "           3             Thomas is widely considered to be one of the m...   \n",
       "           4             This was truly an honor and a pleasure for me ...   \n",
       "...                                                                    ...   \n",
       "2          864           If you'll accept really strong emotions someti...   \n",
       "           865           Highly sensitive people also process informati...   \n",
       "           866           They tend to notice so these that others miss ...   \n",
       "           867           Thank you for listening and hope to see you ne...   \n",
       "           868                                                      Music.   \n",
       "\n",
       "                         confidence  paragraph_number  \n",
       "episode_id chunk_number                                \n",
       "0          0                   0.80                 1  \n",
       "           1                   0.88                 1  \n",
       "           2                   0.90                 1  \n",
       "           3                   0.80                 2  \n",
       "           4                   0.88                 2  \n",
       "...                             ...               ...  \n",
       "2          864                 0.90               178  \n",
       "           865                 0.91               178  \n",
       "           866                 0.81               178  \n",
       "           867                 0.85               179  \n",
       "           868                  NaN               180  \n",
       "\n",
       "[3037 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_knowledge_base(\n",
    "    knowledge_base_dir,\n",
    "):\n",
    "    \"\"\"Load knowledge base.\"\"\"\n",
    "    knowledge_base_dir = Path(knowledge_base_dir)\n",
    "    transcript_data = pandas.read_parquet(knowledge_base_dir / \"transcript_data.parquet\")\n",
    "    episode_data = pandas.read_parquet(knowledge_base_dir / \"episode_data.parquet\")\n",
    "\n",
    "    return {\n",
    "        \"transcript_data\": transcript_data, \n",
    "        \"episode_data\": episode_data,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000035?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'engine'"
     ]
    }
   ],
   "source": [
    "from engine import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "knowledge_base = load_knowledge_base(\n",
    "    knowledge_base_dir=\"../../data/knowledge_base/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>paragraph_number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>6.398</td>\n",
       "      <td>The following is a conversation with demouth c...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.602</td>\n",
       "      <td>16.615</td>\n",
       "      <td>A company that has published and build some of...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.828</td>\n",
       "      <td>30.299</td>\n",
       "      <td>All by itself to play the game of Go better th...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.088</td>\n",
       "      <td>40.678</td>\n",
       "      <td>Thomas is widely considered to be one of the m...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.873</td>\n",
       "      <td>50.563</td>\n",
       "      <td>This was truly an honor and a pleasure for me ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>1192</th>\n",
       "      <td>10258.852</td>\n",
       "      <td>10267.146</td>\n",
       "      <td>it was a pleasure\\nthanks for listening to thi...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>10267.620</td>\n",
       "      <td>10271.611</td>\n",
       "      <td>And now let me leave you with some words from ...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>10272.518</td>\n",
       "      <td>10279.659</td>\n",
       "      <td>Your assumptions are your windows on the world...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>10280.683</td>\n",
       "      <td>10283.674</td>\n",
       "      <td>Thank you for listening and hope to see you ne...</td>\n",
       "      <td>0.87</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>10285.040</td>\n",
       "      <td>10300.200</td>\n",
       "      <td>Music.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4234 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         chunk_start  chunk_end  \\\n",
       "episode_id chunk_number                           \n",
       "0          0                   0.018      6.398   \n",
       "           1                   6.602     16.615   \n",
       "           2                  16.828     30.299   \n",
       "           3                  31.088     40.678   \n",
       "           4                  40.873     50.563   \n",
       "...                              ...        ...   \n",
       "3          1192            10258.852  10267.146   \n",
       "           1193            10267.620  10271.611   \n",
       "           1194            10272.518  10279.659   \n",
       "           1195            10280.683  10283.674   \n",
       "           1196            10285.040  10300.200   \n",
       "\n",
       "                                                                      text  \\\n",
       "episode_id chunk_number                                                      \n",
       "0          0             The following is a conversation with demouth c...   \n",
       "           1             A company that has published and build some of...   \n",
       "           2             All by itself to play the game of Go better th...   \n",
       "           3             Thomas is widely considered to be one of the m...   \n",
       "           4             This was truly an honor and a pleasure for me ...   \n",
       "...                                                                    ...   \n",
       "3          1192          it was a pleasure\\nthanks for listening to thi...   \n",
       "           1193          And now let me leave you with some words from ...   \n",
       "           1194          Your assumptions are your windows on the world...   \n",
       "           1195          Thank you for listening and hope to see you ne...   \n",
       "           1196                                                     Music.   \n",
       "\n",
       "                         confidence  paragraph_number  \n",
       "episode_id chunk_number                                \n",
       "0          0                   0.80                 1  \n",
       "           1                   0.88                 1  \n",
       "           2                   0.90                 1  \n",
       "           3                   0.80                 2  \n",
       "           4                   0.88                 2  \n",
       "...                             ...               ...  \n",
       "3          1192                0.80               244  \n",
       "           1193                0.91               244  \n",
       "           1194                0.88               245  \n",
       "           1195                0.87               246  \n",
       "           1196                 NaN               247  \n",
       "\n",
       "[4234 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_base[\"transcript_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220701 lex_ai_demis_hassabis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220617 lex_ai_richard_wolff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220628 lex_ai_susan_cain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20220122 lex_ai_yann_lecun_2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name\n",
       "episode_id                                \n",
       "0           20220701 lex_ai_demis_hassabis\n",
       "1            20220617 lex_ai_richard_wolff\n",
       "2               20220628 lex_ai_susan_cain\n",
       "3             20220122 lex_ai_yann_lecun_2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knowledge_base[\"episode_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('podcastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "96d68fc9e01005523a1f3667425ef5c40e869ab60af9b33393435084a5f8635b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
