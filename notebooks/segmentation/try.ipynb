{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcript ETL Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandera\n",
      "  Downloading pandera-0.11.0-py3-none-any.whl (115 kB)\n",
      "     ------------------------------------ 115.9/115.9 kB 754.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandera) (1.19.2)\n",
      "Requirement already satisfied: pydantic in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandera) (1.9.0)\n",
      "Collecting typing-inspect>=0.6.0\n",
      "  Downloading typing_inspect-0.7.1-py3-none-any.whl (8.4 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandera) (1.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandera) (21.3)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandera) (8.0.0)\n",
      "Collecting pandas>=1.2.0\n",
      "  Downloading pandas-1.4.3-cp38-cp38-win_amd64.whl (10.6 MB)\n",
      "     ---------------------------------------- 10.6/10.6 MB 3.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from packaging>=20.0->pandera) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=1.2.0->pandera) (2020.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from pandas>=1.2.0->pandera) (2.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from typing-inspect>=0.6.0->pandera) (4.2.0)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.2.0->pandera) (1.15.0)\n",
      "Installing collected packages: mypy-extensions, typing-inspect, pandas, pandera\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.4\n",
      "    Uninstalling pandas-1.1.4:\n",
      "      Successfully uninstalled pandas-1.1.4\n",
      "Successfully installed mypy-extensions-0.4.3 pandas-1.4.3 pandera-0.11.0 typing-inspect-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pandera.typing import DataFrame\n",
    "\n",
    "import pandas\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../..')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_dir = Path(\"../../\")\n",
    "project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../../data/podcasts')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "podcast_dir = project_dir / \"data/podcasts/\"\n",
    "podcast_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('../../data/transcripts/Google')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_dir = project_dir / \"data/transcripts/Google\"\n",
    "transcript_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive H has no label.\n",
      " Volume Serial Number is 6684-7A77\n",
      "\n",
      " Directory of H:\\wav2vec_pre\\podcast-ai-lab\\data\\transcripts\\Google\n",
      "\n",
      "09-07-2022  21:58    <DIR>          .\n",
      "09-07-2022  21:58    <DIR>          ..\n",
      "09-07-2022  21:58           231,318 20220617 lex_ai_richard_wolff.json\n",
      "09-07-2022  21:58           183,984 20220617 lex_ai_richard_wolff.vtt\n",
      "09-07-2022  21:58           174,166 20220628 lex_ai_susan_cain.json\n",
      "09-07-2022  21:58           141,336 20220628 lex_ai_susan_cain.vtt\n",
      "09-07-2022  21:58           249,734 20220701 lex_ai_demis_hassabis.json\n",
      "09-07-2022  21:58           168,142 20220701 lex_ai_demis_hassabis.vtt\n",
      "               6 File(s)      1,148,680 bytes\n",
      "               2 Dir(s)  172,918,071,296 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls {transcript_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_transcript_path = transcript_dir / \"20220701 lex_ai_demis_hassabis.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_transcript_to_dataframe(\n",
    "    path,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Parse Google Speech to Text API result .json -> pandas.DataFrame\"\"\"\n",
    "    transcript_data = pandas.read_json(path)\n",
    "    return transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav2vec_transcript_to_dataframe(\n",
    "    path,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Parse Wav2Vec result .csv -> pandas.DataFrame\"\"\"\n",
    "    transcript_data = pandas.read_csv(path)\n",
    "    return transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_google_transcript(\n",
    "    path,\n",
    "    episode_id: int = None,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Parse Google Speech to Text API result .json -> pandas.DataFrame\"\"\"\n",
    "    transcript_data = pandas.read_json(path)\n",
    "    #transcript_data[\"file_name\"] = path.stem\n",
    "    transcript_data[\"episode_id\"] = episode_id\n",
    "    return transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_google_transcript(\n",
    "    transcript_data,\n",
    ") -> DataFrame:\n",
    "    \"\"\"Clean Google Speech to Text API result.\"\"\"\n",
    "    transcript_data = (\n",
    "        transcript_data\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"start\": \"chunk_start\",\n",
    "                \"end\": \"chunk_end\",\n",
    "                \"newpara\": \"new_paragraph\"\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    transcript_data[\"new_paragraph\"] = transcript_data[\"new_paragraph\"].fillna(0.0).astype(bool)\n",
    "    transcript_data[\"chunk_number\"] = transcript_data.index\n",
    "    # enumerate paragraphs\n",
    "    transcript_data[\"paragraph_number\"] = transcript_data[\"new_paragraph\"].cumsum()\n",
    "    transcript_data = transcript_data.drop(columns=[\"new_paragraph\"])\n",
    "    return transcript_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transcripts(\n",
    "    transcript_dir,\n",
    "):\n",
    "    \"\"\"Process all transcripts in a directory.\"\"\"\n",
    "    transcript_paths = [\n",
    "        p for p in transcript_dir.glob(\"*.json\")\n",
    "    ]\n",
    "    transcript_data = [\n",
    "        clean_google_transcript(parse_google_transcript(path, episode_id)) for episode_id, path in enumerate(transcript_paths)\n",
    "    ]\n",
    "    episode_data = pandas.DataFrame(\n",
    "        [\n",
    "            {\"episode_id\": episode_id, \"file_name\": path.stem}\n",
    "            for episode_id, path in enumerate(transcript_paths)\n",
    "        ]\n",
    "    )\n",
    "    transcript_data = pandas.concat(transcript_data)\n",
    "    transcript_data = transcript_data.set_index([\"episode_id\", \"chunk_number\"])\n",
    "    episode_data = episode_data.set_index(\"episode_id\")\n",
    "    return transcript_data, episode_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- chunk enumeration\n",
    "- file id / name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>episode_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th>paragraph_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>6.398</td>\n",
       "      <td>The following is a conversation with demouth c...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.602</td>\n",
       "      <td>16.615</td>\n",
       "      <td>A company that has published and build some of...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.828</td>\n",
       "      <td>30.299</td>\n",
       "      <td>All by itself to play the game of Go better th...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.088</td>\n",
       "      <td>40.678</td>\n",
       "      <td>Thomas is widely considered to be one of the m...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.873</td>\n",
       "      <td>50.563</td>\n",
       "      <td>This was truly an honor and a pleasure for me ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>8172.342</td>\n",
       "      <td>8184.166</td>\n",
       "      <td>Human beings in this giant puzzle of ours and ...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>None</td>\n",
       "      <td>921</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>8184.954</td>\n",
       "      <td>8191.394</td>\n",
       "      <td>Thanks for listening to this conversation with...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>None</td>\n",
       "      <td>922</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>8191.689</td>\n",
       "      <td>8195.580</td>\n",
       "      <td>And now let me leave you with some words from ...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>None</td>\n",
       "      <td>923</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>8196.244</td>\n",
       "      <td>8202.197</td>\n",
       "      <td>Computer science is no more about computers an...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>None</td>\n",
       "      <td>924</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>8207.280</td>\n",
       "      <td>8222.328</td>\n",
       "      <td>Music.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>925</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>926 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunk_start  chunk_end  \\\n",
       "0          0.018      6.398   \n",
       "1          6.602     16.615   \n",
       "2         16.828     30.299   \n",
       "3         31.088     40.678   \n",
       "4         40.873     50.563   \n",
       "..           ...        ...   \n",
       "921     8172.342   8184.166   \n",
       "922     8184.954   8191.394   \n",
       "923     8191.689   8195.580   \n",
       "924     8196.244   8202.197   \n",
       "925     8207.280   8222.328   \n",
       "\n",
       "                                                  text  confidence episode_id  \\\n",
       "0    The following is a conversation with demouth c...        0.80       None   \n",
       "1    A company that has published and build some of...        0.88       None   \n",
       "2    All by itself to play the game of Go better th...        0.90       None   \n",
       "3    Thomas is widely considered to be one of the m...        0.80       None   \n",
       "4    This was truly an honor and a pleasure for me ...        0.88       None   \n",
       "..                                                 ...         ...        ...   \n",
       "921  Human beings in this giant puzzle of ours and ...        0.81       None   \n",
       "922  Thanks for listening to this conversation with...        0.81       None   \n",
       "923  And now let me leave you with some words from ...        0.91       None   \n",
       "924  Computer science is no more about computers an...        0.91       None   \n",
       "925                                             Music.         NaN       None   \n",
       "\n",
       "     chunk_number  paragraph_number  \n",
       "0               0                 1  \n",
       "1               1                 1  \n",
       "2               2                 1  \n",
       "3               3                 2  \n",
       "4               4                 2  \n",
       "..            ...               ...  \n",
       "921           921               203  \n",
       "922           922               204  \n",
       "923           923               205  \n",
       "924           924               206  \n",
       "925           925               207  \n",
       "\n",
       "[926 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_data = clean_google_transcript(\n",
    "    parse_google_transcript(\n",
    "        transcript_dir / \"20220701 lex_ai_demis_hassabis.json\"\n",
    "    )\n",
    ")\n",
    "transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data.to_csv('transcript.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcript_data, episode_data = process_transcripts(\n",
    "    transcript_dir=transcript_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20220617 lex_ai_richard_wolff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20220628 lex_ai_susan_cain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20220701 lex_ai_demis_hassabis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 file_name\n",
       "episode_id                                \n",
       "0            20220617 lex_ai_richard_wolff\n",
       "1               20220628 lex_ai_susan_cain\n",
       "2           20220701 lex_ai_demis_hassabis"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "episode_data.to_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        DataFrame\n",
       "\u001b[1;31mString form:\u001b[0m\n",
       "file_name\n",
       "           episode_id\n",
       "           0           <...> chard_wolff\n",
       "           1               20220628 lex_ai_susan_cain\n",
       "           2           20220701 lex_ai_demis_hassabis\n",
       "\u001b[1;31mLength:\u001b[0m      3\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\users\\acer\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
       "\n",
       "Data structure also contains labeled axes (rows and columns).\n",
       "Arithmetic operations align on both row and column labels. Can be\n",
       "thought of as a dict-like container for Series objects. The primary\n",
       "pandas data structure.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
       "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
       "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
       "    which have an index defined, it is aligned by its index.\n",
       "\n",
       "    .. versionchanged:: 0.25.0\n",
       "       If data is a list of dicts, column order follows insertion-order.\n",
       "\n",
       "index : Index or array-like\n",
       "    Index to use for resulting frame. Will default to RangeIndex if\n",
       "    no indexing information part of input data and no index provided.\n",
       "columns : Index or array-like\n",
       "    Column labels to use for resulting frame when data does not have them,\n",
       "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
       "    will perform column selection instead.\n",
       "dtype : dtype, default None\n",
       "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
       "copy : bool or None, default None\n",
       "    Copy data from inputs.\n",
       "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
       "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
       "\n",
       "    .. versionchanged:: 1.3.0\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
       "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
       "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
       "read_table : Read general delimited file into DataFrame.\n",
       "read_clipboard : Read text from clipboard into DataFrame.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Constructing DataFrame from a dictionary.\n",
       "\n",
       ">>> d = {'col1': [1, 2], 'col2': [3, 4]}\n",
       ">>> df = pd.DataFrame(data=d)\n",
       ">>> df\n",
       "   col1  col2\n",
       "0     1     3\n",
       "1     2     4\n",
       "\n",
       "Notice that the inferred dtype is int64.\n",
       "\n",
       ">>> df.dtypes\n",
       "col1    int64\n",
       "col2    int64\n",
       "dtype: object\n",
       "\n",
       "To enforce a single dtype:\n",
       "\n",
       ">>> df = pd.DataFrame(data=d, dtype=np.int8)\n",
       ">>> df.dtypes\n",
       "col1    int8\n",
       "col2    int8\n",
       "dtype: object\n",
       "\n",
       "Constructing DataFrame from a dictionary including Series:\n",
       "\n",
       ">>> d = {'col1': [0, 1, 2, 3], 'col2': pd.Series([2, 3], index=[2, 3])}\n",
       ">>> pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
       "   col1  col2\n",
       "0     0   NaN\n",
       "1     1   NaN\n",
       "2     2   2.0\n",
       "3     3   3.0\n",
       "\n",
       "Constructing DataFrame from numpy ndarray:\n",
       "\n",
       ">>> df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
       "...                    columns=['a', 'b', 'c'])\n",
       ">>> df2\n",
       "   a  b  c\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9\n",
       "\n",
       "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
       "\n",
       ">>> data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
       "...                 dtype=[(\"a\", \"i4\"), (\"b\", \"i4\"), (\"c\", \"i4\")])\n",
       ">>> df3 = pd.DataFrame(data, columns=['c', 'a'])\n",
       "...\n",
       ">>> df3\n",
       "   c  a\n",
       "0  3  1\n",
       "1  6  4\n",
       "2  9  7\n",
       "\n",
       "Constructing DataFrame from dataclass:\n",
       "\n",
       ">>> from dataclasses import make_dataclass\n",
       ">>> Point = make_dataclass(\"Point\", [(\"x\", int), (\"y\", int)])\n",
       ">>> pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
       "   x  y\n",
       "0  0  0\n",
       "1  0  3\n",
       "2  2  3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episode_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>chunk_start</th>\n",
       "      <th>chunk_end</th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>paragraph_number</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>episode_id</th>\n",
       "      <th>chunk_number</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.018</td>\n",
       "      <td>6.398</td>\n",
       "      <td>The following is a conversation with demouth c...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.602</td>\n",
       "      <td>16.615</td>\n",
       "      <td>A company that has published and build some of...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.828</td>\n",
       "      <td>30.299</td>\n",
       "      <td>All by itself to play the game of Go better th...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31.088</td>\n",
       "      <td>40.678</td>\n",
       "      <td>Thomas is widely considered to be one of the m...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40.873</td>\n",
       "      <td>50.563</td>\n",
       "      <td>This was truly an honor and a pleasure for me ...</td>\n",
       "      <td>0.88</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th>864</th>\n",
       "      <td>7495.120</td>\n",
       "      <td>7503.117</td>\n",
       "      <td>If you'll accept really strong emotions someti...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>7503.708</td>\n",
       "      <td>7511.174</td>\n",
       "      <td>Highly sensitive people also process informati...</td>\n",
       "      <td>0.91</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>7511.783</td>\n",
       "      <td>7521.274</td>\n",
       "      <td>They tend to notice so these that others miss ...</td>\n",
       "      <td>0.81</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>7522.478</td>\n",
       "      <td>7525.730</td>\n",
       "      <td>Thank you for listening and hope to see you ne...</td>\n",
       "      <td>0.85</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>7526.960</td>\n",
       "      <td>7542.264</td>\n",
       "      <td>Music.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3037 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         chunk_start  chunk_end  \\\n",
       "episode_id chunk_number                           \n",
       "0          0                   0.018      6.398   \n",
       "           1                   6.602     16.615   \n",
       "           2                  16.828     30.299   \n",
       "           3                  31.088     40.678   \n",
       "           4                  40.873     50.563   \n",
       "...                              ...        ...   \n",
       "2          864              7495.120   7503.117   \n",
       "           865              7503.708   7511.174   \n",
       "           866              7511.783   7521.274   \n",
       "           867              7522.478   7525.730   \n",
       "           868              7526.960   7542.264   \n",
       "\n",
       "                                                                      text  \\\n",
       "episode_id chunk_number                                                      \n",
       "0          0             The following is a conversation with demouth c...   \n",
       "           1             A company that has published and build some of...   \n",
       "           2             All by itself to play the game of Go better th...   \n",
       "           3             Thomas is widely considered to be one of the m...   \n",
       "           4             This was truly an honor and a pleasure for me ...   \n",
       "...                                                                    ...   \n",
       "2          864           If you'll accept really strong emotions someti...   \n",
       "           865           Highly sensitive people also process informati...   \n",
       "           866           They tend to notice so these that others miss ...   \n",
       "           867           Thank you for listening and hope to see you ne...   \n",
       "           868                                                      Music.   \n",
       "\n",
       "                         confidence  paragraph_number  \n",
       "episode_id chunk_number                                \n",
       "0          0                   0.80                 1  \n",
       "           1                   0.88                 1  \n",
       "           2                   0.90                 1  \n",
       "           3                   0.80                 2  \n",
       "           4                   0.88                 2  \n",
       "...                             ...               ...  \n",
       "2          864                 0.90               178  \n",
       "           865                 0.91               178  \n",
       "           866                 0.81               178  \n",
       "           867                 0.85               179  \n",
       "           868                  NaN               180  \n",
       "\n",
       "[3037 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcript_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_knowledge_base(\n",
    "    knowledge_base_dir,\n",
    "):\n",
    "    \"\"\"Load knowledge base.\"\"\"\n",
    "    transcript_data = pandas.read_parquet(knowledge_base_dir / \"transcript_data.parquet\")\n",
    "    episode_data = pandas.read_parquet(knowledge_base_dir / \"episode_data.parquet\")\n",
    "\n",
    "    return {\n",
    "        \"transcript_data\": transcript_data, \n",
    "        \"episode_data\": episode_data,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000035?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m config\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'engine'"
     ]
    }
   ],
   "source": [
    "from engine import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=0'>1</a>\u001b[0m load_knowledge_base(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=1'>2</a>\u001b[0m     knowledge_base_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m../../data/knowledge_base/\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;32m/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb Cell 28\u001b[0m in \u001b[0;36mload_knowledge_base\u001b[0;34m(knowledge_base_dir)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_knowledge_base\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=1'>2</a>\u001b[0m     knowledge_base_dir,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=2'>3</a>\u001b[0m ):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=3'>4</a>\u001b[0m     \u001b[39m\"\"\"Load knowledge base.\"\"\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=4'>5</a>\u001b[0m     transcript_data \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mread_parquet(knowledge_base_dir \u001b[39m/\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtranscript_data.parquet\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=5'>6</a>\u001b[0m     episode_data \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mread_parquet(knowledge_base_dir \u001b[39m/\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mepisode_data.parquet\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=8'>9</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtranscript_data\u001b[39m\u001b[39m\"\u001b[39m: transcript_data, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=9'>10</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mepisode_data\u001b[39m\u001b[39m\"\u001b[39m: episode_data,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/cls/Documents/Work/Projects/SoundOfAI/podcast-ai-lab/notebooks/transcription/dev-transcript-etl.ipynb#ch0000033?line=10'>11</a>\u001b[0m     }\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'str'"
     ]
    }
   ],
   "source": [
    "load_knowledge_base(\n",
    "    knowledge_base_dir=\"../../data/knowledge_base/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "96d68fc9e01005523a1f3667425ef5c40e869ab60af9b33393435084a5f8635b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
